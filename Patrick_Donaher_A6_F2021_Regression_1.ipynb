{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patrick Donaher A6 F2021 Regression 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFHvr3sOU066"
      },
      "source": [
        "**Rationale** This assignment will help you practice running and interpreting basic regressions analysis.\n",
        "\n",
        "**[Datasets](https://drive.google.com/drive/folders/1LJ38ctVX62ggGGygJDLlLG2V6jZ4BNml?usp=sharing)**\n",
        "1. [Safegraph Temple Visitor Sample](https://drive.google.com/file/d/1u_sDxFp9fja-_cop4yzIAJ_hX2-fplWN/view?usp=sharing) \n",
        "1. [Avocado Prices](https://drive.google.com/file/d/1QJ_dyyBFkHhC6VkzVvdAFa385mtqtntM/view?usp=sharing)\n",
        "\n",
        "**Data description** This dataset includes SafeGraph's sampled foot traffic volume for Temple University between 1-1-2019 and 5-31-2020. Safegraph collects the foot traffic data from a network of phone apps. You can view the `visits` data as the number of SafeGraph tracked devices to visit Temple University. This dataset is merged with Philadelphia's weather data. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMiIPD5fTfBa"
      },
      "source": [
        "# 1. Run and interpret a simple linear regression (5 points)...\n",
        "...to figure out the relationship between daily average temperateure as measured in degrees fahrenheit, `\"temp\"`, and people on campus `\"visits\"` for the Fall 2019 semester (limit data to M-F 8-26 - 11-24-2019, inclusive).\n",
        "\n",
        "In your answer: \n",
        "1. First, look at data. What is the average number of SafeGraph visitors to Temple University during the teaching days of the Fall 2019 semester? Roughly what percent of the Temple student population is this?\n",
        "1. Specify (write out the regression equation), run, and interpret a regression that documents the relationship between temperature and foot traffic (visits) on campus.\n",
        "    1. Do more students visit campus (and presumably go to class) when the weather is warmer or colder?\n",
        "    1. Besides students not wanting to go to class when the temperature is not to their liking, what else might cause the observed relationship between visits and temperature?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsqX3z-sRx36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ee7141-a9dc-4ce4-af22-3bb3d2a2b689"
      },
      "source": [
        "# imports here\n",
        "import os, pandas as pd, matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from statsmodels.formula import api as smf\n",
        "drive.mount('drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp4FG9vZ0ppg",
        "outputId": "32cfe8e3-6d89-41db-90b8-ac7a14b0e5e5"
      },
      "source": [
        "# list directory containing the data\n",
        "fpath = 'drive/MyDrive/A6/' # change this to your data folder\n",
        "os.listdir(fpath)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['temple_traffic.csv', 'avocado.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vmT-l-52Pd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f1322f-1f0a-4e5a-c334-9339b05c4b88"
      },
      "source": [
        "# read in the dataset\n",
        "temple = pd.read_csv(fpath + 'temple_traffic.csv', index_col = 0)\n",
        "temple.columns.values"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['safegraph_place_id', 'date', 'visits', 'stn', 'wban', 'temp',\n",
              "       'count_temp', 'dewp', 'count_dewp', 'slp', 'count_slp', 'stp',\n",
              "       'count_stp', 'visib', 'count_visib', 'wdsp', 'count_wdsp', 'mxspd',\n",
              "       'gust', 'maxtemp', 'flag_max', 'mintemp', 'flag_min', 'prcp',\n",
              "       'flag_prcp', 'sndp', 'frshtt'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7enE1M-JBzd"
      },
      "source": [
        "# convert the date column to pandas datetime using pd.to_datetime(...)\n",
        "# if you've fogotten, look through notes from module 3\n",
        "temple['date'] = pd.to_datetime(temple['date']) \n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqUZKoCvKi3M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "f8227d65-e38b-40fe-a5fe-f2d1a84e0435"
      },
      "source": [
        "# create a new column called 'dow' (for day of week) using temple.date.dt.weekday\n",
        "# note that Monday through Sunday corresponds to 0 through 6\n",
        "temple[\"dow\"] = (temple.date.dt.weekday)\n",
        "temple\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>safegraph_place_id</th>\n",
              "      <th>date</th>\n",
              "      <th>visits</th>\n",
              "      <th>stn</th>\n",
              "      <th>wban</th>\n",
              "      <th>temp</th>\n",
              "      <th>count_temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>count_dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>count_slp</th>\n",
              "      <th>stp</th>\n",
              "      <th>count_stp</th>\n",
              "      <th>visib</th>\n",
              "      <th>count_visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>count_wdsp</th>\n",
              "      <th>mxspd</th>\n",
              "      <th>gust</th>\n",
              "      <th>maxtemp</th>\n",
              "      <th>flag_max</th>\n",
              "      <th>mintemp</th>\n",
              "      <th>flag_min</th>\n",
              "      <th>prcp</th>\n",
              "      <th>flag_prcp</th>\n",
              "      <th>sndp</th>\n",
              "      <th>frshtt</th>\n",
              "      <th>dow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-03-02</td>\n",
              "      <td>65</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>45.8</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.8</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63.3</td>\n",
              "      <td>*</td>\n",
              "      <td>34.7</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>68</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59.9</td>\n",
              "      <td>*</td>\n",
              "      <td>45.9</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-03-04</td>\n",
              "      <td>71</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>51.4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58.6</td>\n",
              "      <td>*</td>\n",
              "      <td>45.1</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>70</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>49.2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55.8</td>\n",
              "      <td>*</td>\n",
              "      <td>41.7</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>57</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>41.7</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1013.1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>49.1</td>\n",
              "      <td>*</td>\n",
              "      <td>37.2</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-02-19</td>\n",
              "      <td>122</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1020.9</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58.1</td>\n",
              "      <td>*</td>\n",
              "      <td>43.0</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-02-20</td>\n",
              "      <td>100</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>37.1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.3</td>\n",
              "      <td>*</td>\n",
              "      <td>31.6</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>107</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>29.7</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1031.6</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.1</td>\n",
              "      <td>*</td>\n",
              "      <td>23.0</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-02-22</td>\n",
              "      <td>63</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>37.1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1026.9</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.3</td>\n",
              "      <td>*</td>\n",
              "      <td>28.4</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>sg:00579e722c8e48178ef0c66a7c91f92c</td>\n",
              "      <td>2020-02-23</td>\n",
              "      <td>66</td>\n",
              "      <td>997286.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>43.3</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1022.8</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55.9</td>\n",
              "      <td>*</td>\n",
              "      <td>31.1</td>\n",
              "      <td>*</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>518 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      safegraph_place_id       date  visits  ...  sndp  frshtt  dow\n",
              "0    sg:00579e722c8e48178ef0c66a7c91f92c 2020-03-02      65  ...   NaN     0.0    0\n",
              "1    sg:00579e722c8e48178ef0c66a7c91f92c 2020-03-03      68  ...   NaN     0.0    1\n",
              "2    sg:00579e722c8e48178ef0c66a7c91f92c 2020-03-04      71  ...   NaN     0.0    2\n",
              "3    sg:00579e722c8e48178ef0c66a7c91f92c 2020-03-05      70  ...   NaN     0.0    3\n",
              "4    sg:00579e722c8e48178ef0c66a7c91f92c 2020-03-06      57  ...   NaN     0.0    4\n",
              "..                                   ...        ...     ...  ...   ...     ...  ...\n",
              "513  sg:00579e722c8e48178ef0c66a7c91f92c 2020-02-19     122  ...   NaN     0.0    2\n",
              "514  sg:00579e722c8e48178ef0c66a7c91f92c 2020-02-20     100  ...   NaN     0.0    3\n",
              "515  sg:00579e722c8e48178ef0c66a7c91f92c 2020-02-21     107  ...   NaN     0.0    4\n",
              "516  sg:00579e722c8e48178ef0c66a7c91f92c 2020-02-22      63  ...   NaN     0.0    5\n",
              "517  sg:00579e722c8e48178ef0c66a7c91f92c 2020-02-23      66  ...   NaN     0.0    6\n",
              "\n",
              "[518 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4btKbsJT_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153577d5-2d17-4e44-cb93-6cd789fb91ec"
      },
      "source": [
        "# select only the rows where the date lies between 2019/8/26 and 2019/11/24 (inclusive) \n",
        "# and correspond to a regular school date (e.g. are M-F)\n",
        "# call the reuslting dataframe F2019\n",
        "# remember you can select rows using df.loc[conditions]\n",
        "# If you forgot how to do this, look at the notes and in class exercise from module 3\n",
        "\n",
        "F2019 = ((temple['date'] >= '2019-8-26') & (temple['date'] <= '2019-11-24') & (temple['dow'] < 5))\n",
        "print(temple.loc[F2019])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      safegraph_place_id       date  visits  ...  sndp  frshtt  dow\n",
            "7    sg:00579e722c8e48178ef0c66a7c91f92c 2019-09-23     169  ...   NaN     0.0    0\n",
            "8    sg:00579e722c8e48178ef0c66a7c91f92c 2019-09-24     182  ...   NaN     0.0    1\n",
            "9    sg:00579e722c8e48178ef0c66a7c91f92c 2019-09-25     156  ...   NaN     0.0    2\n",
            "10   sg:00579e722c8e48178ef0c66a7c91f92c 2019-09-26     168  ...   NaN     0.0    3\n",
            "11   sg:00579e722c8e48178ef0c66a7c91f92c 2019-09-27     165  ...   NaN     0.0    4\n",
            "..                                   ...        ...     ...  ...   ...     ...  ...\n",
            "504  sg:00579e722c8e48178ef0c66a7c91f92c 2019-11-11     117  ...   NaN     0.0    0\n",
            "505  sg:00579e722c8e48178ef0c66a7c91f92c 2019-11-12     106  ...   NaN     0.0    1\n",
            "506  sg:00579e722c8e48178ef0c66a7c91f92c 2019-11-13     106  ...   NaN     0.0    2\n",
            "507  sg:00579e722c8e48178ef0c66a7c91f92c 2019-11-14     107  ...   NaN     0.0    3\n",
            "508  sg:00579e722c8e48178ef0c66a7c91f92c 2019-11-15     114  ...   NaN     0.0    4\n",
            "\n",
            "[65 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vxvJXQ8KDNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25d1161-321a-4a1f-f6a5-b89eed2ecb15"
      },
      "source": [
        "# find the maximum date of F2019, make sure that it is less than or equal to 2019/11/24\n",
        "(temple.loc[F2019]).date.max()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2019-11-22 00:00:00')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRdjXtSGKMpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac65bff6-628f-41ca-eda1-957e65e663f3"
      },
      "source": [
        "# find the minimum date of F2019, make sure that it is greater than or equal to 2019/8/26\n",
        "(temple.loc[F2019]).date.min()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2019-08-26 00:00:00')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3woD6jmTKhXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfde3b49-0bff-40a4-f681-6a55720cf99d"
      },
      "source": [
        "# display the unique values of dow in F2019 (use the .unique() method on dow column)\n",
        "# make sure there are only M-F (e.g. 0-4)\n",
        "(temple.loc[F2019]).dow.unique()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWMllbS92PhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2a667c-2e7a-4c98-f39e-864c0bda46cf"
      },
      "source": [
        "# compute the mean visits\n",
        "mean_visits = (temple.loc[F2019]).visits.mean()\n",
        "mean_visits\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137.73846153846154"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNv3QYQlIIWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba91e9e0-da95-4721-d6b0-b7d8844be656"
      },
      "source": [
        "# look up the total number of temple students in 2019 and compute the percentage the above average represents\n",
        "Fall2019TotalEnrollment = 39088\n",
        "mean_visits/Fall2019TotalEnrollment*100\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3523804275953273"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DngEeFYSH9g7"
      },
      "source": [
        "**Edit this cell**\n",
        "The average number of visitors in the sample is **____137_______**, this is approximately **___.35______**\\% of the Temple student population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaHre7HHH9lW"
      },
      "source": [
        "**Edit this cell**\n",
        "\n",
        "Before running a regression to document the relationship between temperature and the sampled visitors, answer the following.\n",
        "\n",
        "The logical dependent variable should be **_____visits____________**, the logical indepdent (aka explanatory) variable should be **______Temp__________** because **__number of temp__(degrees of Farenheight)__________** should cause changes in **____number of visits____________** and not the other way around.\n",
        "\n",
        "\n",
        "Consequently, the following regression equation describes the relationship between temperature and foot traffic (change the $x$ and $y$ to the approriate variable names):\n",
        "\n",
        "$$\n",
        "y = \\beta_0 +\\beta_1x + e \n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-y0o9jRIZBt"
      },
      "source": [
        "# run the above regression using statsmodels\n",
        "# call the resulting regression results object the variable \"res\"\n",
        "res = smf.ols('visits ~ temp', data = (temple.loc[F2019])).fit()\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB0ui4NIIZE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "04e00b7e-b700-4231-bfa8-d3cf22c3abc9"
      },
      "source": [
        "# print the regression summary table (e.g. print(res.summary()))\n",
        "res.summary()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>visits</td>      <th>  R-squared:         </th> <td>   0.468</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.459</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   55.33</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 19 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>3.43e-10</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>19:25:49</td>     <th>  Log-Likelihood:    </th> <td> -285.36</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    65</td>      <th>  AIC:               </th> <td>   574.7</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    63</td>      <th>  BIC:               </th> <td>   579.1</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   40.8564</td> <td>   13.255</td> <td>    3.082</td> <td> 0.003</td> <td>   14.369</td> <td>   67.343</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>temp</th>      <td>    1.5446</td> <td>    0.208</td> <td>    7.438</td> <td> 0.000</td> <td>    1.130</td> <td>    1.960</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 7.362</td> <th>  Durbin-Watson:     </th> <td>   1.359</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.025</td> <th>  Jarque-Bera (JB):  </th> <td>   6.733</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.639</td> <th>  Prob(JB):          </th> <td>  0.0345</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.922</td> <th>  Cond. No.          </th> <td>    344.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                 visits   R-squared:                       0.468\n",
              "Model:                            OLS   Adj. R-squared:                  0.459\n",
              "Method:                 Least Squares   F-statistic:                     55.33\n",
              "Date:                Tue, 19 Oct 2021   Prob (F-statistic):           3.43e-10\n",
              "Time:                        19:25:49   Log-Likelihood:                -285.36\n",
              "No. Observations:                  65   AIC:                             574.7\n",
              "Df Residuals:                      63   BIC:                             579.1\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     40.8564     13.255      3.082      0.003      14.369      67.343\n",
              "temp           1.5446      0.208      7.438      0.000       1.130       1.960\n",
              "==============================================================================\n",
              "Omnibus:                        7.362   Durbin-Watson:                   1.359\n",
              "Prob(Omnibus):                  0.025   Jarque-Bera (JB):                6.733\n",
              "Skew:                          -0.639   Prob(JB):                       0.0345\n",
              "Kurtosis:                       3.922   Cond. No.                         344.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPJQfl1DM6Ym"
      },
      "source": [
        "**Edit this cell**\n",
        "\n",
        "The regression's R$^2$ is **_____.468__________**, this suggests that **_______46.8________**\\% of the variation in **______Visits________** is explained by **_____Temp__________**.\n",
        "\n",
        "The intercept ($\\beta_0$) is **_____40.8564___________**, this means that when **____temperature in Farehight_(and all explanatory variables)_______** is 0 **(fill in appropriate units of measure)**, **_______Visits_________** is on average **________40.8564_________**. This is statistically **significant**, meaning that it is different from **_____the null hypothesis__________** in the population.\n",
        "\n",
        "The coefficient ($\\beta_1$) for **_____temp_________** is **_______1.5446________**. This means that for every **________1 degree farenheight_________** increase in **______temp___________**, **___visits________________** **increases** by **_______1.5446______________**. This is statistically **significant**, meaning that it is different from **______0 since p < .05__________** in the population. In other words, we can reject the null hypothesis that there is no effect of temperature on campus foot traffic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfC8WyR1RP5X"
      },
      "source": [
        "# 2. Avocado price and demand (5 points) (multiple regression)\n",
        "\n",
        "For this exercise, use our familiar avocado dataset.\n",
        "\n",
        "For the following cities, run a multiple regression that investigates the relationship between demand and price while simultaneously accounting for the effect of regions.\n",
        "\n",
        "Use only the conventional avocado data from the following cities:\n",
        "\n",
        "```\n",
        "cities = ['Philadelphia', 'NewYork', 'BaltimoreWashington', 'Boston', 'Chicago', 'SanFrancisco']\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsMuz0YMSHdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "7be1beb3-c942-4292-d013-3d43ff5461f2"
      },
      "source": [
        "# read in the dataset, call it avocado\n",
        "avocado = pd.read_csv(fpath + 'avocado.csv', index_col = 0)\n",
        "avocado.head()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>AveragePrice</th>\n",
              "      <th>Total Volume</th>\n",
              "      <th>4046</th>\n",
              "      <th>4225</th>\n",
              "      <th>4770</th>\n",
              "      <th>Total Bags</th>\n",
              "      <th>Small Bags</th>\n",
              "      <th>Large Bags</th>\n",
              "      <th>XLarge Bags</th>\n",
              "      <th>type</th>\n",
              "      <th>year</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-12-27</td>\n",
              "      <td>1.33</td>\n",
              "      <td>64236.62</td>\n",
              "      <td>1036.74</td>\n",
              "      <td>54454.85</td>\n",
              "      <td>48.16</td>\n",
              "      <td>8696.87</td>\n",
              "      <td>8603.62</td>\n",
              "      <td>93.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-12-20</td>\n",
              "      <td>1.35</td>\n",
              "      <td>54876.98</td>\n",
              "      <td>674.28</td>\n",
              "      <td>44638.81</td>\n",
              "      <td>58.33</td>\n",
              "      <td>9505.56</td>\n",
              "      <td>9408.07</td>\n",
              "      <td>97.49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-12-13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>118220.22</td>\n",
              "      <td>794.70</td>\n",
              "      <td>109149.67</td>\n",
              "      <td>130.50</td>\n",
              "      <td>8145.35</td>\n",
              "      <td>8042.21</td>\n",
              "      <td>103.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-12-06</td>\n",
              "      <td>1.08</td>\n",
              "      <td>78992.15</td>\n",
              "      <td>1132.00</td>\n",
              "      <td>71976.41</td>\n",
              "      <td>72.58</td>\n",
              "      <td>5811.16</td>\n",
              "      <td>5677.40</td>\n",
              "      <td>133.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-11-29</td>\n",
              "      <td>1.28</td>\n",
              "      <td>51039.60</td>\n",
              "      <td>941.48</td>\n",
              "      <td>43838.39</td>\n",
              "      <td>75.78</td>\n",
              "      <td>6183.95</td>\n",
              "      <td>5986.26</td>\n",
              "      <td>197.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  AveragePrice  Total Volume  ...          type  year  region\n",
              "0  2015-12-27          1.33      64236.62  ...  conventional  2015  Albany\n",
              "1  2015-12-20          1.35      54876.98  ...  conventional  2015  Albany\n",
              "2  2015-12-13          0.93     118220.22  ...  conventional  2015  Albany\n",
              "3  2015-12-06          1.08      78992.15  ...  conventional  2015  Albany\n",
              "4  2015-11-29          1.28      51039.60  ...  conventional  2015  Albany\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOJ8Rrl7Rifv"
      },
      "source": [
        "# select only the rows corresponding to the cities listed above\n",
        "# call the resulting dataframe avocado (replace avocado with the result of this subset selection)\n",
        "# use .isin(...) method (see notes from module 4 bar plot to find an example of this)\n",
        "# also make sure to select only the data for the conventional avocado type\n",
        "cities = ['Philadelphia', 'NewYork', 'BaltimoreWashington', 'Boston', 'Chicago', 'SanFrancisco']\n",
        "avocado = avocado[(avocado.region.isin(cities))&(avocado.type=='conventional')].copy()\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-2TrTERiiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8aa608-ab32-48ce-8364-6a0007425f77"
      },
      "source": [
        "# show the unique regions in the resulting dataframe \n",
        "# make sure we have only the ones we wanted to select from above\n",
        "avocado.region.unique()\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BaltimoreWashington', 'Boston', 'Chicago', 'NewYork',\n",
              "       'Philadelphia', 'SanFrancisco'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df-5xO72UfQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92bea09d-b67f-455e-d2bb-4c854de1403f"
      },
      "source": [
        "# show the unique types in the resulting dataframe \n",
        "# make sure we have only conventional\n",
        "avocado.type.unique()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['conventional'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPfImhR6TnpB"
      },
      "source": [
        "**edit this cell**\n",
        "To model the demand of avocaldos, we want to run the following regression:\n",
        "\n",
        "$$\n",
        "Demand = \\beta_0 + \\beta_1 Price +\\beta_2 Boston +\\beta_3Chicago +\\beta_4NewYork + \\beta_5 Philadelphia + \\beta_6 SanFrancisco +e\n",
        "$$\n",
        "\n",
        "In this equation (given the cities we've selected for the dataset), $\\beta_0$ represents the average demand in **____________** when price is \\$ $0$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7tnkt4TWZwS"
      },
      "source": [
        "# since statsmodels expects variable names to not have spaces\n",
        "# use a list comprehension to replace  spaces with underscores\n",
        "# make sure you understand how/why this works:\n",
        "avocado.columns = [c.replace(' ', '_') for c in avocado.columns]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8kYfHkyWs3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3b7440-2099-488f-b7b0-4c37212c9f93"
      },
      "source": [
        "# take a look at the resulting dataframe\n",
        "avocado.columns\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'AveragePrice', 'Total_Volume', '4046', '4225', '4770',\n",
              "       'Total_Bags', 'Small_Bags', 'Large_Bags', 'XLarge_Bags', 'type', 'year',\n",
              "       'region'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExG_RDNsRilF"
      },
      "source": [
        "# run the regression using statsmodels\n",
        "# call the result object res\n",
        "# for demand, use 'Total Bags'\n",
        "\n",
        "res = smf.ols('Total_Bags ~ C(region) + AveragePrice', data = avocado).fit()\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgIUxo1tW3A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65ca30b-d955-46fa-e47b-6d38bc43f9fb"
      },
      "source": [
        "# print the regression summary table\n",
        "print(res.summary())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:             Total_Bags   R-squared:                       0.765\n",
            "Model:                            OLS   Adj. R-squared:                  0.764\n",
            "Method:                 Least Squares   F-statistic:                     546.7\n",
            "Date:                Tue, 19 Oct 2021   Prob (F-statistic):          1.30e-312\n",
            "Time:                        19:25:50   Log-Likelihood:                -12529.\n",
            "No. Observations:                1014   AIC:                         2.507e+04\n",
            "Df Residuals:                    1007   BIC:                         2.511e+04\n",
            "Df Model:                           6                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=============================================================================================\n",
            "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------------\n",
            "Intercept                  1.847e+05   1.05e+04     17.671      0.000    1.64e+05    2.05e+05\n",
            "C(region)[T.Boston]       -8.097e+04   6144.983    -13.177      0.000    -9.3e+04   -6.89e+04\n",
            "C(region)[T.Chicago]      -9.941e+04   6141.100    -16.188      0.000   -1.11e+05   -8.74e+04\n",
            "C(region)[T.NewYork]       1.843e+05   6152.184     29.961      0.000    1.72e+05    1.96e+05\n",
            "C(region)[T.Philadelphia]  -6.29e+04   6149.588    -10.229      0.000    -7.5e+04   -5.08e+04\n",
            "C(region)[T.SanFrancisco] -1.097e+05   6149.942    -17.839      0.000   -1.22e+05   -9.76e+04\n",
            "AveragePrice               8121.8105   7073.444      1.148      0.251   -5758.568     2.2e+04\n",
            "==============================================================================\n",
            "Omnibus:                      586.949   Durbin-Watson:                   0.765\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10971.908\n",
            "Skew:                           2.262   Prob(JB):                         0.00\n",
            "Kurtosis:                      18.467   Cond. No.                         12.9\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSggG2udW8vP"
      },
      "source": [
        "**Edit this cell**\n",
        "1. The R$^2$ is **______.765__________**, this means that **______76.5%__________**\\% of the variation in demand is explained by the model.\n",
        "1. The intercept ($\\beta_0$) is **______184700_______** and is statistically **significant**. This is the average demand in **_____Total Bags_________** when price is \\$0.\n",
        "1. The coefficient for Boston is **______-.0008129__________**, which means that the average demand in Boston is **____.0008129________** **fewer** bags than in **____The average city_____________**. This difference is statistically **significant**\n",
        "1. The coefficient for price is **_____8121.8105__________**, which means that when price increases by \\$1 in any region, demand increases by on average **_______8121.8105_______** bags. This effect is statistically **insignificant** which means that there is enough evidence to show that price **does** have an **positive** impact on demand.\n",
        "1. The region with the highest demand is **________NewYork__________**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_w3rvOfS9AJ"
      },
      "source": [
        "# 3. Putting what we've learned all together (the power of programming) (2 points - extra point for bonus, try your best - there may or may not be a prize involved)\n",
        "\n",
        "In this exercise, you will run one regression for each region and each avocado type, i.e. one regression of total bags sold on price for Philly conventional, one for Philly organic, one for NY conventional, one for NY organic, and so on... (think loop). \n",
        "\n",
        "You will then visualize the coefficients for conventional and organic price by region on a scatter plot (each dot's (x, y) coordinates = one region's (price coefficient for conventional, price coefficient for organic). \n",
        "\n",
        "To do this break down the problem to the following components (and then put it all together):\n",
        "\n",
        "* Suppose you have selected a region $r$ and avocado type $t$, how would you run the regression?\n",
        "* How can you extract just the price coefficient given a regression result object `res`?\n",
        "* For some region, `r`, and some avocado type `t`, how would you select only the rows pertaining to region `r` and type `t`?\n",
        "* How can you loop through regions and types? (Need 2 nested \"for\" loops, one inside the other)\n",
        "* Suppose you have named the conventional and organic price coefficients for region `r` as `bConv` and `bOrg`, how would you create a list that looks like: `[region, conventional coeff, organic coefficient]`?\n",
        "* Given a list `results`, how would you *append* the list above to `results`? i.e. make keep adding to `results`: `[[region1, conventional coeff1, organic coeff1], [region2, conventional coeff2, organic coeff2], [region3, conventional coeff3, organic coeff3],...]`\n",
        "* Once you've run every regression and have a complete `results` list, convert it to a dataframe using `df = pd.DataFrame(results)`, give it some column names.\n",
        "\n",
        "The final code might have a structure similar to the pseudo code below:\n",
        "\n",
        "```\n",
        "results = list()\n",
        "for r in ##all the unique regions##:\n",
        "    for t in ##all the unique types##:\n",
        "        temp = # Select the appropriate rows of df\n",
        "        # run the regression using temp\n",
        "        if ##this iteration represents conventional avocados##:\n",
        "            ##extract the price parameter assign it to the variable bConv##\n",
        "        else:\n",
        "            ##extract the price parameter and name it bOrg##\n",
        "    ##append the results with newest [region, conventional price coeff, organic price coefficient]##\n",
        "df = pd.DataFrame(results) # convert to dataframe\n",
        "df.columns = ['region', 'beta_conv', 'beta_org'] # rename dataframe columns\n",
        "```\n",
        "\n",
        "The resulting dataframe of coefficients should look something like:\n",
        "\n",
        "| region | beta_conv | beta_org |\n",
        "|-|-|-|\n",
        "| Albany |8.579340e+02\t |-3168.491384|\n",
        "| Atlanta| -3.377365e+05 | -6352.937420 |\n",
        "| BaltimoreWashington | -3.251570e+05 | -15537.003211 |\n",
        "|...|...|...|...|\n",
        "\n",
        "(note numbers above are illustrative, not necessarily representative of actual results)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o6lf_eohCkm"
      },
      "source": [
        "# first re-read the original avocado dataframe to use for this problem\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdCOaQydkjyt"
      },
      "source": [
        "# rename columns to get rid of spaces\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnpfGJQEcnB6"
      },
      "source": [
        "# run all the regressions\n",
        "# create a dataframe with region, beta_conv, beta_org as the 3 columns \n",
        "# using the regression results\n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqMCmqKjd_e4"
      },
      "source": [
        "# Get rid of the TotalUS region from the regression results dataframe\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmtNXW9kdJrH"
      },
      "source": [
        "# show the full resulting table\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5ob8DzqdVnh"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sObNE08meO1C"
      },
      "source": [
        "# make scatter plot of the coefficients\n",
        "# change aesthetics so the dots are not a single blob\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP80H3UmeU2T"
      },
      "source": [
        "# which regions have upward sloping demand curve for organic (as price increases, so did demand)?\n",
        "# use code to show these rows of df\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5ytO-GevTU"
      },
      "source": [
        "# which regions have upward sloping demand curve for conventional (as price increases, so did demand)?\n",
        "# use code to show these rows of df\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dir5sgD7e1Ki"
      },
      "source": [
        "Why might the relationship between price and demand be upward sloping instead of the expected downward sloping demand curve theorized in economics? i.e. the law of demand, when price increases, demand decreases. \n",
        "\n",
        "**Your answer here**"
      ]
    }
  ]
}